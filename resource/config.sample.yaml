server:
  listen: ":2045"
  name: "default"
  dsn: "sqlite:./data.db"
  staticPath: "./resource/static"

  downlaodMaxWorker: 1
  saveDir: "./download"
  cacheDir: "./download/cache"
  httpClientProxy: ""

log:
  path: "./log/log.log"
  level: "debug"
  maxSize: 10 #  M
  maxAge: 30 # days


groq:
  apiKey: ""

translation:
  deeplX:
    url: ""
    apiKey: ""
  openAiCompatible:
    baseUrl: ""
    apiKey: ""
    model: ""
    systemPrompt: "You are a professional, authentic machine translation engine."
    prompt: ";; Treat next line as plain text input and translate it into {{.targetLang}},output translation ONLY. If translation is unnecessary (e.g. proper nouns, codes, etc.), return the original text.If a newline character is encountered: '\n' then each result is output as a newline character. NO explanations. NO notes. Input: {{.text}}"




#subtitle:
#  watch: false
#  pattern: "(?i)\\.(mp4|avi|mkv|mov|wmv|flv|webm|rmvb|asf)$"
#  dirPath: ""
#  subtitleInput:
#    provider: "ggml-medium"
#    prompt: ""
#    temperature:
#    language: ""
#    translateTo: ""
#    blacklist: []
#  blacklistFilePath: ./blacklist.txt
#  lockFilePath: ./.lock

# sherpa:
#   embeddingModelPath: "path/to/3dspeaker_speech_eres2net_base_sv_zh-cn_3dspeaker_16k.onnx"
#   pyannoteModelPath: "path/to/sherpa-onnx-pyannote-segmentation-3-0/model.onnx"
#   offlineModelConfig:
#     # Configuration for offline/non-streaming transducer.
#     # Please refer to
#     # https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html
#     # to download pre-trained models
#     transducer:
#       encoder: "eee"
#       decoder: ""
#       joiner: ""
#     paraformer:
#       # Configuration for offline/non-streaming paraformer.
#       # please refer to
#       # https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html
#       # to download pre-trained models
#       model: ""
#     nemoctc:
#       #  Configuration for offline/non-streaming NeMo CTC models.
#       #
#       #  Please refer to
#       #  https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html
#       #  to download pre-trained models
#       model: ""
#     whisper:
#       decoder: "path/to/sherpa-onnx-paraformer-zh-2023-09-14/model.int8.onnx"
#       encoder: "path/to/sherpa-onnx-whisper-tiny.en/tiny.en-encoder.onnx"
#       language: ""
#       task: ""
#       tailpaddings: 0
#     tdnn:
#       model: ""
#     sensevoice:
#       model: "path/to/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx"
#       language: ""
#       useinversetextnormalization: 0
#     moonshine:
#       preprocessor: ""
#       encoder: ""
#       uncacheddecoder: ""
#       cacheddecoder: ""
#     tokens: "path/to/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt"
#     numthreads: 4
#     debug: 1
#     provider: "cpu" # 可选值: cpu, cuda, coreml
#     modeltype: "senseVoice" # 可选
#     modelingunit: "cjkchar" # 可选: cjkchar, bpe, cjkchar+bpe
#     bpevocab: "" # 可选
#     telespeechctc: "" # 可选