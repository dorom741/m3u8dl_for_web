server:
  listen: ":2045"
  name: "default"
  dsn: "sqlite:./data.db"
  staticPath: "./resource/static"

  downlaodMaxWorker: 1
  saveDir: "./download"
  cacheDir: "./download/cache"
  httpClientProxy: ""

log:
  path: "./log/log.log"
  level: "debug"
  maxSize: 10 #  M
  maxAge: 30 # days



groq:
  apiKey: ""



openai_prompt: &openai_prompt
  systemPrompt: >
    - Role: Professional Translator
    - Background: The user needs to translate specific phrases, requiring the translation to be smooth and accurate in the target language by considering the context. The user prefers to receive the translation directly without additional explanations.
    - Profile: You are an experienced professional translator with proficiency in multiple languages. You have a deep understanding of linguistic semantics, grammar, and cultural contexts, and can accurately translate phrases based on context.
    - Skills: You possess strong language analysis skills, cross-cultural communication abilities, and a keen sense for context. You can ensure the accuracy and smoothness of translations.
    - Goals: Translate the provided phrase into the target language, ensuring it is smooth and accurate based on the context.
    - Constrains: The translation must accurately convey the original phrase's meaning, adhere to the target language's grammar and expression habits, and avoid literal translation. Provide the translation directly without additional explanations.
    - OutputFormat: Directly output the translated phrase.outputting only the translation result without any original text. make the target language fluent. If a line break is encountered: '\n', then each result is output as a line break. No explanation. No comment.
    - Workflow:
      1. Understand the literal meaning and context of the original phrase.
      2. Analyze the grammatical structure and expression habits of the target language.
      3. Translate the phrase directly, ensuring it is smooth and accurate based on the context.
    - Examples:
      - Example 1: Original phrase: "He is always late." (Context: Friends' gathering)
        Translate to English: He is always late for the party.
      - Example 2: Original phrase: "This plan is not feasible." (Context: Business meeting)
        Translate to English: This plan is not feasible.
      - Example 3: Original phrase: "I have fallen in love with this city." (Context: Travel journal)
        Translate to English: I have fallen in love with this city.
    - Initialization: In the first conversation, please directly output the following: Hello! As a professional translator, I will directly translate phrases based on context for you. Please provide the phrase you need to translate, its context, and the target language.
  prompt: "translate it to {{.targetLang}}: {{.text}}"


translation:
  providers:
    - name: deeplx
      enable: true
      type: deeplx
      deepLXConfig:
        RPM: 0
        urlsFile: urls.txt
        urls:
          - ""

    - name: openai
      enable: true
      type: openai
      openaiConfig:
        baseUrl: ""
        apiKey: ""
        model: ""
        contextLen: 20
        <<: *openai_prompt

    
    - name: google
      enable: true
      type: google
      googleTranslationConfig:
        multipleTextSeparator: "\n"
        RPM: 100

    

whisperCppClientConfig:
  inferenceUrl: http://127.0.0.1:8080/inference_async
  inferenceResultUrl: http://127.0.0.1:8080/inference_result
  async: true
  splitDuration: 3600
  debugMode: true

# lateralProviderConfig:
#   inferenceUrl: http://127.0.0.1:2045/api/addGenerateSubtitleTaskAsync
#   inferenceResultUrl: http://127.0.0.1:2045/api/getTaskResult
#   splitDuration: 3600
#   taskTimeoutDuration: 12h
#   provider: "sherpa"
#   bearerToken:





#subtitle:
#  watch: false
#  pattern: "(?i)\\.(mp4|avi|mkv|mov|wmv|flv|webm|rmvb|asf)$"
#  dirPath: ""
#  subtitleInput:
#    provider: "ggml-medium"
#    prompt: ""
#    temperature:
#    language: ""
#    translateTo: ""
#    blacklist: []
#  blacklistFilePath: ./blacklist.txt
#  lockFilePath: ./.lock

# sherpa:
#   splitDuration: 3600
#   embeddingModelPath: "path/to/3dspeaker_speech_eres2net_base_sv_zh-cn_3dspeaker_16k.onnx"
#   pyannoteModelPath: "path/to/sherpa-onnx-pyannote-segmentation-3-0/model.onnx"
#   offlineModelConfig:
#     # Configuration for offline/non-streaming transducer.
#     # Please refer to
#     # https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-transducer/index.html
#     # to download pre-trained models
#     transducer:
#       encoder: "eee"
#       decoder: ""
#       joiner: ""
#     paraformer:
#       # Configuration for offline/non-streaming paraformer.
#       # please refer to
#       # https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-paraformer/index.html
#       # to download pre-trained models
#       model: ""
#     nemoctc:
#       #  Configuration for offline/non-streaming NeMo CTC models.
#       #
#       #  Please refer to
#       #  https://k2-fsa.github.io/sherpa/onnx/pretrained_models/offline-ctc/index.html
#       #  to download pre-trained models
#       model: ""
#     whisper:
#       decoder: "path/to/sherpa-onnx-paraformer-zh-2023-09-14/model.int8.onnx"
#       encoder: "path/to/sherpa-onnx-whisper-tiny.en/tiny.en-encoder.onnx"
#       language: ""
#       task: ""
#       tailpaddings: 0
#     tdnn:
#       model: ""
#     sensevoice:
#       model: "path/to/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/model.int8.onnx"
#       language: ""
#       useinversetextnormalization: 0
#     moonshine:
#       preprocessor: ""
#       encoder: ""
#       uncacheddecoder: ""
#       cacheddecoder: ""
#     tokens: "path/to/sherpa-onnx-sense-voice-zh-en-ja-ko-yue-2024-07-17/tokens.txt"
#     numthreads: 4
#     debug: 1
#     provider: "cpu" # 可选值: cpu, cuda, coreml
#     modeltype: "senseVoice" # 可选
#     modelingunit: "cjkchar" # 可选: cjkchar, bpe, cjkchar+bpe
#     bpevocab: "" # 可选
#     telespeechctc: "" # 可选